cos(0.7267382)-0.7267382+1/10
# Création du vecteur X1
x1=c(23.8,16.3,27.2,7.1,25.1,27.5,19.4,19.8,32.2,20.7)
# création du vecteur y
y=c(115.4,76.8,113.8,81.6,115.4,125,83.6,75.2,136.8,102.8)
plot(x1,y)
# Calcul du coéficient de corrélation linéaire
cor(x1,y)
# Mise en place du modèle linéaire simple
mls=lm(y~x1)
# Estimation des paramètres du modèle
summary(mls)
# Variation résiduelle (SCR)
SCR=sum(mls$residuals^2)
# Calcul de la stat tetachapeau
teta_carr=(1/(10-2))*SCR
# Calcul de la moyenne de Y
moy_x1=mean(x1)
# Prédiction des valeurs de Y
pred_x1=predict(mls)
# Variation totale pour les Xi
SC=sum((x1 - moy_x1)^2)
# Calcul de la région critique
w=teta_carr*(1/SC)
# Affichage
w
# Calcul du quantile d'ordre 1-a/2 de la loi de student
qt(0.975,8)
b_1=2.6306
# Variation résiduelle (SCR)
SCR=sum(mls$residuals^2)
# Calcul de la stat tetachapeau
teta_carr=(1/(10-2))*SCR
# Calcul de la moyenne de Y
moy_x1=mean(x1)
# Prédiction des valeurs de Y
pred_x1=predict(mls)
# Variation totale pour les Xi
SC=sum((x1 - moy_x1)^2)
# Calcul de la région critique
t=teta_carr*(1/SC)
w=(b_1)*(1/t)
# Affichage
w
# Calcul du quantile d'ordre 1-a/2 de la loi de student
qt(0.975,8)
setwd("C:/Users/HP/OneDrive - UNIVERSITE DES LAGUNES/Bureau/PROGRAM/TP_CNS")
data("iris")
iris=data("iris")
iris
donne=data("iris")
donne
data("iris")
?iris
naniar::vis_miss(data("iris"))
#data("iris")
data("iris", package = "datasets")
Data = iris
sample_n(Data,10)
#data("iris")
library(SciViews)
data("iris", package = "datasets")
Data = iris
sample_n(Data,10)
#data("iris")
library(dplyr)
data("iris", package = "datasets")
Data = iris
sample_n(Data,10)
naniar::vis_miss(Data)
skimr::skim(urchin2)
#data("iris")
library(dplyr)
data("iris", package = "datasets")
Data_iris = iris
sample_n(Data_iris,10)
naniar::vis_miss(Data_iris)
naniar::vis_miss(Data_iris)
skimr::skim(Data_iris)
View(Data_iris)
View(Data_iris)
library(SciViews)
iris_cor <- correlation(Data_iris[,-1])
library(SciViews)
iris_cor <- correlation(Data_iris[:, -1])
library(SciViews)
iris_cor <- correlation(Data_iris[, 1:4])
knitr::kable(iris_cor, digits = 2)
library(SciViews)
iris_cor <- correlation(Data_iris[, 1:4])
knitr::kable(iris_cor, digits = 2)
plot(iris_cor)
library(SciViews)
iris_cor <- correlation(Data_iris[, 1:4])
knitr::kable(iris_cor, digits = 2)
plot(iris_cor)
library(FactoMineR)
iris_pca <- PCA(Data_iris[, 1:4],ncp = 4,scale.unit = TRUE, quali.sup = 4,
graph = F)
var <- get_pca_var(iris_pca)
library(FactoMineR)
var = get_pca_var(iris_pca)
library(factoextra)
var = get_pca_var(iris_pca)
var$coord
library(factoextra)
eig.val <- get_eigenvalue(iris_pca)
eig.val
var = get_pca_var(iris_pca)
var$coord
library(factoextra)
eig.val = get_eigenvalue(iris_pca)
eig.val
var = get_pca_var(iris_pca)
var$coord
fviz_eig(iris_pca, addlabels = TRUE, ylim = c(0, 40))
fviz_eig(iris_pca, addlabels = TRUE, ylim = c(0, 110))
fviz_eig(iris_pca, addlabels = TRUE, ylim = c(0, 90))
plot.PCA(iris_pca, axes = c(1,2), choix = 'ind',)
plot.PCA(iris_pca, axes = c(1,2),
choix = 'var',
title = "Graphe des variables")
plot.PCA(iris_pca, axes = c(1,2), choix = 'ind',)
plot.PCA(iris_pca, axes = c(1,2), choix = 'ind',)
Investigate(iris_pca)
library(FactoInvestigate)
Investigate(iris_pca)
library(FactoInvestigate)
Investigate(iris_pca)
library(FactoMineR)
iris_pca = PCA(Data_iris[, 1:5],ncp = 4,scale.unit = TRUE, quali.sup = 4,
graph = F)
library(FactoMineR)
iris_pca = PCA(Data_iris[, 1:4],ncp = 4,scale.unit = TRUE, quali.sup = 4,
graph = F)
library(factoextra)
eig.val = get_eigenvalue(iris_pca)
eig.val
var = get_pca_var(iris_pca)
var$coord
fviz_eig(iris_pca, addlabels = TRUE, ylim = c(0, 90))
plot.PCA(iris_pca, axes = c(1,2),
choix = 'var',
title = "Graphe des variables")
plot.PCA(iris_pca, axes = c(1,2), choix = 'ind',)
library(FactoInvestigate)
Investigate(iris_pca)
library(FactoMineR)
iris_pca = PCA(Data_iris[, 2:4],ncp = 4,scale.unit = TRUE, quali.sup = 4,
graph = F)
library(FactoMineR)
iris_pca = PCA(Data_iris[, 1:4],ncp = 4,scale.unit = TRUE, quali.sup = 4,
graph = F)
library(FactoMineR)
iris_pca = PCA(Data_iris[, 0:4],ncp = 4,scale.unit = TRUE, quali.sup = 4,
graph = F)
library(FactoInvestigate)
Investigate(iris_pca)
library(FactoMineR)
iris_pca = PCA(Data_iris[, 0:4],ncp = 4,scale.unit = TRUE, quali.sup = 4,
graph = F)
library(factoextra)
eig.val = get_eigenvalue(iris_pca)
eig.val
var = get_pca_var(iris_pca)
var$coord
fviz_eig(iris_pca, addlabels = TRUE, ylim = c(0, 90))
plot.PCA(iris_pca, axes = c(1,2),
choix = 'var',
title = "Graphe des variables")
plot.PCA(iris_pca, axes = c(1,2), choix = 'ind',)
library(FactoInvestigate)
Investigate(iris_pca)
library(FactoInvestigate)
Investigate(iris_pca)
library(FactoMineR)
iris_pca = PCA(Data_iris[,1:4],ncp = 4,scale.unit = TRUE, quali.sup = 4,
graph = F)
#data("iris")
library(dplyr)
data("iris", package = "datasets")
Data_iris = iris
sample_n(Data_iris,10)
naniar::vis_miss(Data_iris)
skimr::skim(Data_iris)
library(SciViews)
iris_cor <- correlation(Data_iris[, 1:4])
knitr::kable(iris_cor, digits = 2)
plot(iris_cor)
library(FactoMineR)
iris_pca = PCA(Data_iris[,1:4],ncp = 4,scale.unit = TRUE, quali.sup = 4,
graph = F)
library(factoextra)
eig.val = get_eigenvalue(iris_pca)
eig.val
var = get_pca_var(iris_pca)
var$coord
fviz_eig(iris_pca, addlabels = TRUE, ylim = c(0, 90))
plot.PCA(iris_pca, axes = c(1,2),
choix = 'var',
title = "Graphe des variables")
plot.PCA(iris_pca, axes = c(1,2), choix = 'ind',)
library(FactoInvestigate)
Investigate(iris_pca)
library(FactoInvestigate)
resulta=prcomp(iris_pca)
library(FactoMineR)
iris_pca = PCA(Data_iris[,1:4])
library(FactoMineR)
iris_pca = PCA(Data_iris[,1:4],scale.unit = TRUE,
graph = F)
library(factoextra)
eig.val = get_eigenvalue(iris_pca)
eig.val
var = get_pca_var(iris_pca)
var$coord
fviz_eig(iris_pca, addlabels = TRUE, ylim = c(0, 90))
plot.PCA(iris_pca, axes = c(1,2),
choix = 'var',
title = "Graphe des variables")
plot.PCA(iris_pca, axes = c(1,2), choix = 'ind',)
library(FactoInvestigate)
Investigate(iris_pca)
library(dplyr)
data("iris", package = "datasets")
data_Set = iris
sample_n(data_Set,10)
#definition de la methde de linkage
m = c( "average", "single", "complete", "ward")
names(m) = c( "average", "single", "complete", "ward")
#fonction agglomérative
ac = function(x) {
agnes(df, method = x)$ac
}
#Identification de la méthode de linkage method
sapply(m, ac)
library(cluster)
#definition de la methde de linkage
m = c( "average", "single", "complete", "ward")
names(m) = c( "average", "single", "complete", "ward")
#fonction agglomérative
ac = function(x) {
agnes(df, method = x)$ac
}
#Identification de la méthode de linkage method
sapply(m, ac)
library(dplyr)
data("iris", package = "datasets")
df = iris
sample_n(df,10)
library(cluster)
#definition de la methde de linkage
m = c( "average", "single", "complete", "ward")
names(m) = c( "average", "single", "complete", "ward")
#fonction agglomérative
ac = function(x) {
agnes(df, method = x)$ac
}
#Identification de la méthode de linkage method
sapply(m, ac)
library(cluster)
clust == agnes(df, method = "ward")
library(cluster)
clust == agnes(df, method = "ward")
library(cluster)
clust = agnes(df, method = "ward")
#Calcul gap statistique pour chaque nombre de cluster
gap_stat <- clusGap(df, FUN = hcut, nstart = 25, K.max = 10, B = 50)
#Calcul gap statistique pour chaque nombre de cluster
gap_stat = clusGap(df, FUN = hcut, nstart = 25, K.max = 10, B = 50)
#Calcul gap statistique pour chaque nombre de cluster
gap_stat = clusGap(df[, 1:4], FUN = hcut, nstart = 25, K.max = 10, B = 50)
library(cluster)
#definition de la methde de linkage
m = c( "average", "single", "complete", "ward")
names(m) = c( "average", "single", "complete", "ward")
#fonction agglomérative
ac = function(x) {
agnes(df[, 1:4], method = x)$ac
}
#Identification de la méthode de linkage method
sapply(m, ac)
library(cluster)
clust = agnes(df[, 1:4], method = "ward")
#Calcul gap statistique pour chaque nombre de cluster
gap_stat = clusGap(df[, 1:4], FUN = hcut, nstart = 25, K.max = 10, B = 50)
#Visualisation du gap statistic
fviz_gap_stat(gap_stat)
# 1. ACP
res.pca = PCA(df[, 1:4], ncp = 3,graph = FALSE)
# 2. HCPC
res.hcpc = HCPC(res.pca,
nb.clust = 6,
metric = "euclidean",
method = "ward",
graph = FALSE)
#Affichage du nombre d'élément de chaque cluster
table(res.hcpc$data.clust[,5])
fviz_dend(res.hcpc,
cex = 0.7,                     # Taille du text
palette = "jco",               # Palette de couleur ?ggpubr::ggpar
rect = TRUE, rect_fill = TRUE, # Rectangle autour des groupes
rect_border = "jco",           # Couleur du rectangle
labels_track_height = 0.8      # Augment l'espace pour le texte
)
#dendogramme
library(dendextend)
library(igraph)
library(tidyverse)
library(factoextra)
fviz_dend(res.hcpc,
cex = 0.7,                     # Taille du text
palette = "jco",               # Palette de couleur ?ggpubr::ggpar
rect = TRUE, rect_fill = TRUE, # Rectangle autour des groupes
rect_border = "jco",           # Couleur du rectangle
labels_track_height = 0.8      # Augment l'espace pour le texte
)
#library(dendextend)
library(igraph)
library(tidyverse)
library(factoextra)
fviz_cluster(res.hcpc,
repel = TRUE,            # Evite le chevauchement des textes
show.clust.cent = TRUE, # Montre le centre des clusters
palette = "jco",         # Palette de couleurs, voir ?ggpubr::ggpar
ggtheme = theme_minimal(),
main = "Factor map"
)
library(FactoInvestigate)
Investigate(res.hcpc)
# Chargement de donnée
library(dplyr)
data("iris", package = "datasets")
df = iris
sample_n(df,10)
# Charge le package kohonen
library(kohonen)
#Paramètrage
set.seed(100)
carte <- som(as.matrix(df[, 1:4]), grid = somgrid(xdim=5, ydim=2, topo = c("hexagonal")))
#Résumé de la carte
summary(carte)
# Charge le package kohonen
library(kohonen)
#Paramètrage
set.seed(100)
carte <- som(as.matrix(df[, 1:4]), grid = somgrid(xdim=7, ydim=7, topo = c("hexagonal")))
#Résumé de la carte
summary(carte)
# Charge le package kohonen
library(kohonen)
#Paramètrage
set.seed(100)
carte = som(as.matrix(df[, 1:4]), grid = somgrid(xdim=7, ydim=7, topo = c("hexagonal")))
#Résumé de la carte
summary(carte)
carte2 = som(as.matrix(df), grid = somgrid(7,7 , topo = "hexagonal"), rlen = 300)
carte2 = som(as.matrix(df[, 1:4]), grid = somgrid(7,7 , topo = "hexagonal"), rlen = 300)
nb = table(carte2$unit.classif)
nb
carte2 = som(as.matrix(df[, 1:4]), grid = somgrid(7,7 , topo = "hexagonal"), rlen = 300)
nb = table(carte2$unit.classif)
plot(carte2,type="dist.neighbours")
#visualisation des classes dans la carte topologique
plot(carte2,type="mapping",
bgcol=c("steelblue1","sienna1","yellowgreen")[groupes])
#découpage en 4 classes
groupes = cutree(cah,k=4)
#matrice de distance entre les noeuds
dis = dist(code)
#foction de calcul des corrélations
weighted.correlation = function(v,w,grille){
x <- grille$grid$pts[,"x"]
y <- grille$grid$pts[,"y"]
mx <- weighted.mean(x,w)
my <- weighted.mean(y,w)
mv <- weighted.mean(v,w)
numx <- sum(w*(x-mx)*(v-mv))
denomx <- sqrt(sum(w*(x-mx)^2))*sqrt(sum(w*(v-mv)^2))
numy <- sum(w*(y-my)*(v-mv))
denomy <- sqrt(sum(w*(y-my)^2))*sqrt(sum(w*(v-mv)^2))
#correlation for the two axes
res <- c(numx/denomx,numy/denomy)
return(res) }
#calcul des corrélations pour l'ensemble des colonnes du codebook
code = carte2$codes[[1]]
CORMAP<-apply(code,2,weighted.correlation,w=nb,grille=carte2)
#foction de calcul des corrélations
weighted.correlation = function(v,w,grille){
x <- grille$grid$pts[,"x"]
y <- grille$grid$pts[,"y"]
mx <- weighted.mean(x,w)
my <- weighted.mean(y,w)
mv <- weighted.mean(v,w)
numx <- sum(w*(x-mx)*(v-mv))
denomx <- sqrt(sum(w*(x-mx)^2))*sqrt(sum(w*(v-mv)^2))
numy <- sum(w*(y-my)*(v-mv))
denomy <- sqrt(sum(w*(y-my)^2))*sqrt(sum(w*(v-mv)^2))
#correlation for the two axes
res <- c(numx/denomx,numy/denomy)
return(res) }
#calcul des corrélations pour l'ensemble des colonnes du codebook
code = carte2$codes[[1]]
#matrice de distance entre les noeuds
dis = dist(code)
#classification
cah = hclust(dis,method="ward.D2",members=nb)
plot(carte2, type = "codes", codeRendering = "segments")
setwd("D:/COURS_DE_KRA/3EME_ANNEE/Semestre2/INFORMATIQUE/CNS")
library(dplyr)
data("iris", package = "datasets")
Data_iris = iris
sample_n(Data_iris,10)
naniar::vis_miss(Data_iris)
skimr::skim(Data_iris)
library(SciViews)
iris_cor <- correlation(Data_iris[, 1:4])
knitr::kable(iris_cor, digits = 2)
plot(iris_cor)
library(FactoMineR)
iris_pca = PCA(Data_iris[,1:4],scale.unit = TRUE,
graph = F)
library(factoextra)
eig.val = get_eigenvalue(iris_pca)
eig.val
var = get_pca_var(iris_pca)
var$coord
fviz_eig(iris_pca, addlabels = TRUE, ylim = c(0, 90))
plot.PCA(iris_pca, axes = c(1,2),
choix = 'var',
title = "Graphe des variables")
plot.PCA(iris_pca, axes = c(1,2), choix = 'ind',)
library(FactoInvestigate)
Investigate(iris_pca)
library(dplyr)
data("iris", package = "datasets")
df = iris
sample_n(df,10)
library(cluster)
#definition de la methde de linkage
m = c( "average", "single", "complete", "ward")
names(m) = c( "average", "single", "complete", "ward")
#fonction agglomérative
ac = function(x) {
agnes(df[, 1:4], method = x)$ac
}
#Identification de la méthode de linkage method
sapply(m, ac)
library(cluster)
clust = agnes(df[, 1:4], method = "ward")
#Calcul gap statistique pour chaque nombre de cluster
gap_stat = clusGap(df[, 1:4], FUN = hcut, nstart = 25, K.max = 10, B = 50)
#Visualisation du gap statistic
fviz_gap_stat(gap_stat)
# 1. ACP
res.pca = PCA(df[, 1:4], ncp = 3,graph = FALSE)
# 2. HCPC
res.hcpc = HCPC(res.pca,
nb.clust = 6,
metric = "euclidean",
method = "ward",
graph = FALSE)
#dendogramme
library(dendextend)
library(igraph)
library(tidyverse)
library(factoextra)
fviz_dend(res.hcpc,
cex = 0.7,                     # Taille du text
palette = "jco",               # Palette de couleur ?ggpubr::ggpar
rect = TRUE, rect_fill = TRUE, # Rectangle autour des groupes
rect_border = "jco",           # Couleur du rectangle
labels_track_height = 0.8      # Augment l'espace pour le texte
)
library(igraph)
library(tidyverse)
library(factoextra)
fviz_cluster(res.hcpc,
repel = TRUE,            # Evite le chevauchement des textes
show.clust.cent = TRUE, # Montre le centre des clusters
palette = "jco",         # Palette de couleurs, voir ?ggpubr::ggpar
ggtheme = theme_minimal(),
main = "Factor map"
)
library(FactoInvestigate)
Investigate(res.hcpc)
# Chargement de donnée
library(dplyr)
data("iris", package = "datasets")
df = iris
sample_n(df,10)
# Charge le package kohonen
library(kohonen)
#Paramètrage
set.seed(100)
carte = som(as.matrix(df[, 1:4]), grid = somgrid(xdim=7, ydim=7, topo = c("hexagonal")))
#Résumé de la carte
summary(carte)
carte2 = som(as.matrix(df[, 1:4]), grid = somgrid(7,7 , topo = "hexagonal"), rlen = 300)
nb = table(carte2$unit.classif)
plot(carte2,type="dist.neighbours")
plot(carte2, type = "codes", codeRendering = "segments")
library(dplyr)
data("iris", package = "datasets")
Data_iris = iris
sample_n(Data_iris,10)
naniar::vis_miss(Data_iris)
skimr::skim(Data_iris)
library(SciViews)
iris_cor <- correlation(Data_iris[, 1:4])
knitr::kable(iris_cor, digits = 2)
plot(iris_cor)
